{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f97ade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98db8c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#possible spectral emissions given as (n, n_prime) which is (sender, reciever)\n",
    "spectral_transitions = [(7, 6), (7, 5), (7, 4), (7, 3), (7, 2), (7, 1),\n",
    "                              (6, 5), (6, 4), (6, 3), (6, 2), (6, 1),\n",
    "                                      (5, 4), (5, 3), (5, 2), (5, 1),\n",
    "                                              (4, 3), (4, 2), (4, 1),\n",
    "                                                      (3, 2), (3, 1), \n",
    "                                                              (2, 1)]\n",
    "\n",
    "#possible spectral width modulations\n",
    "spectral_widths = [\"normal\", \"doubly-ext\", \"UV-ext\", \"IR-ext\", \"UV-dim\", \"IR-dim\"]\n",
    "\n",
    "#possible spectral filtering\n",
    "spectral_filters = [\"none\", \"tri\", \"tri-inv\", \"lo\", \"hi\", \"bp\"]\n",
    "\n",
    "\n",
    "#possible sonic transitions given as [(n, n_prime), can_be_free]\n",
    "sonic_transitions = [[(6, 2), False],\n",
    "                     [(5, 2), True],\n",
    "                     [(4, 2), False],\n",
    "                     [(7, 3), False], \n",
    "                     [(6, 3), True],\n",
    "                     [(7, 4), True],\n",
    "                     [(7, 5), False], \n",
    "                     [(6, 4), False],\n",
    "                     [(5, 3), False]]\n",
    "\n",
    "#possible sonic amplitude modulations \n",
    "sonic_amps = [\"up\", \"down\", \"spike\"]\n",
    "\n",
    "#possible gender transitions\n",
    "gender_transitions = [(7, 1), (6, 1), (5, 1), (4, 1), (3, 1), (2, 1)]\n",
    "possible_genders = [2, 3, 4, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaf464bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spectral:\n",
    "    trans = None\n",
    "    width = None\n",
    "    filter = None\n",
    "    \n",
    "    def __init__(self, trans, width, filter):\n",
    "        self.trans = trans\n",
    "        self.width = width\n",
    "        self.filter = filter \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.trans) + \" \" + self.width + \" \" + self.filter\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.trans) + \" \" + self.width + \" \" + self.filter\n",
    "        \n",
    "        \n",
    "class Sonic:\n",
    "    trans = None\n",
    "    amp = None\n",
    "    \n",
    "    def __init__(self, trans, amp):\n",
    "        self.trans = trans\n",
    "        self.amp = amp\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.trans) + \" \" + self.amp\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.trans) + \" \" + self.amp\n",
    "        \n",
    "        \n",
    "class Morpheme:\n",
    "    spectral = None\n",
    "    sonic1 = None\n",
    "    sonic2 = None\n",
    "    sonic3 = None  #should be sonic \n",
    "    gender = None  #should be list []\n",
    "    haptic = None\n",
    "    \n",
    "    def __init__(self, spectral, sonic1, gender, haptic, sonic2 = None, sonic3 = None):\n",
    "        self.spectral = spectral \n",
    "        self.sonic1 = sonic1\n",
    "        self.gender = gender \n",
    "        self.haptic = haptic\n",
    "        if sonic2 is not None:\n",
    "            self.sonic2 = sonic2\n",
    "        if sonic3 is not None:\n",
    "            self.sonic3 = sonic3\n",
    "            \n",
    "    def __repr__(self):\n",
    "        string = \"\"\n",
    "        string += 'spectral: ' + str(self.spectral) + \"\\n\"\n",
    "        string += 'sonic1: ' + str(self.sonic1) + \"\\n\"\n",
    "        \n",
    "        if self.sonic2 is not None:\n",
    "            string += 'sonic2: ' + str(self.sonic2) + \"\\n\"\n",
    "        if self.sonic3 is not None:\n",
    "            string += 'sonic3: ' + str(self.sonic3) + \"\\n\"\n",
    "        string += 'gender: ' + str(self.gender) + \"\\n\"\n",
    "        string += 'haptic: ' + str(self.haptic) + \"\\n\"\n",
    "        return string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b63bc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_spectral():\n",
    "    #get random transition\n",
    "    #get random width\n",
    "    #get random filter\n",
    "    trans = spectral_transitions[np.random.randint(len(spectral_transitions))]\n",
    "    width = np.random.choice(spectral_widths)\n",
    "    filter = np.random.choice(spectral_filters)\n",
    "    \n",
    "    spectral = Spectral(trans, width, filter)\n",
    "    return spectral\n",
    "\n",
    "def generate_random_sonic():\n",
    "    #get random transition\n",
    "    #if it can be free, add free to the list\n",
    "    #get random amp\n",
    "    \n",
    "    trans_bool = sonic_transitions[np.random.randint(len(sonic_transitions))]\n",
    "    trans = trans_bool[0]\n",
    "    free = trans_bool[1]\n",
    "    \n",
    "    possible_amps = sonic_amps.copy()\n",
    "    if free:\n",
    "        possible_amps.append(\"free\")\n",
    "\n",
    "    amp = np.random.choice(possible_amps)\n",
    "    \n",
    "    sonic = Sonic(trans, amp)\n",
    "    return sonic \n",
    "\n",
    "def generate_random_gender(): #same as generating random haptic \n",
    "    gender = []\n",
    "    \n",
    "    num_genders = np.random.randint(7)\n",
    "    gender_pool = possible_genders.copy()\n",
    "    \n",
    "    for i in range(num_genders):\n",
    "        gender_chosen = np.random.choice(gender_pool)\n",
    "        gender.append(gender_chosen)\n",
    "        gender_pool.remove(gender_chosen)\n",
    "        \n",
    "    return gender\n",
    "\n",
    "\n",
    "\n",
    "def generate_random_morpheme():\n",
    "    #make random spectral\n",
    "    #make 1-3 random sonic\n",
    "    #make random gender \n",
    "    #put it into morpheme \n",
    "    spectral = generate_random_spectral()\n",
    "    sonic1 = generate_random_sonic()\n",
    "    sonic2 = generate_random_sonic()\n",
    "    while sonic2.trans == sonic1.trans:\n",
    "        sonic2 = generate_random_sonic()\n",
    "    sonic3 = generate_random_sonic() \n",
    "    while sonic3.trans == sonic2.trans or sonic3.trans == sonic1.trans:\n",
    "        sonic3 = generate_random_sonic()\n",
    "    \n",
    "    num_sonic = np.random.randint(3, size=1)[0] + 1\n",
    "    \n",
    "    if num_sonic == 2:\n",
    "        sonic3 = None\n",
    "    elif num_sonic == 1:\n",
    "        sonic3 = None\n",
    "        sonic2 = None\n",
    "        \n",
    "    gender = generate_random_gender()\n",
    "    haptic = generate_random_gender()\n",
    "        \n",
    "    morpheme = Morpheme(spectral, sonic1, gender, haptic, sonic2 = sonic2, sonic3 = sonic3)\n",
    "    return morpheme \n",
    "\n",
    "def generate_random_word(): \n",
    "    #make 6 morphemes \n",
    "    #put into a list \n",
    "    word = []\n",
    "    for i in range(6):\n",
    "        morph = generate_random_morpheme()\n",
    "        word.append(morph)\n",
    "    \n",
    "    return word\n",
    "\n",
    "def generate_random_sentence():\n",
    "    #make 21 words\n",
    "    #put into a list\n",
    "    sentence = []\n",
    "    for i in range(21):\n",
    "        word = generate_random_word()\n",
    "        sentence.append(word)\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e090e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hand movement mapping from (width, filter) --> (home-spec for n, home-spec for n_prime)\n",
    "hand_movt_mapping = {\n",
    "    ('normal', 'none'): (\"I<N\", \"I<N\"),\n",
    " ('doubly-ext', 'none'): (\"I<E\", \"I<E\"),\n",
    " ('UV-ext', 'none'): (\"I<E\", \"I<N\"),\n",
    " ('IR-ext', 'none'): (\"I<N\", \"I<E\"),\n",
    " ('UV-dim', 'none'): (\"I<D\", \"I<N\"),\n",
    " ('IR-dim', 'none'): (\"I<N\", \"I<D\"),\n",
    "    \n",
    " ('normal', 'tri'): (\"D<N\", \"D<N\"), \n",
    " ('doubly-ext', 'tri'): (\"D<E\", \"D<E\"),\n",
    " ('UV-ext', 'tri'): (\"D<E\", \"D<N\"),\n",
    " ('IR-ext', 'tri'): (\"D<N\", \"D<E\"),\n",
    " ('UV-dim', 'tri'): (\"D<D\", \"D<N\"),\n",
    " ('IR-dim', 'tri'): (\"D<N\", \"D<D\"),\n",
    "    \n",
    " ('normal', 'tri-inv'): (\"U<N\", \"U<N\"),\n",
    " ('doubly-ext', 'tri-inv'): (\"U<E\", \"U<E\"),\n",
    " ('UV-ext', 'tri-inv'): (\"U<E\", \"U<N\"),\n",
    " ('IR-ext', 'tri-inv'): (\"U<N\", \"U<E\"),\n",
    " ('UV-dim', 'tri-inv'): (\"U<D\", \"U<N\"),\n",
    " ('IR-dim', 'tri-inv'): (\"U<N\", \"U<D\"),\n",
    "    \n",
    " ('normal', 'lo'): (\"U<N\", \"D<N\"),\n",
    " ('doubly-ext', 'lo'): (\"U<E\", \"D<E\"),\n",
    " ('UV-ext', 'lo'): (\"U<E\", \"D<N\"),\n",
    " ('IR-ext', 'lo'): (\"U<N\", \"D<E\"),\n",
    " ('UV-dim', 'lo'): (\"U<D\", \"D<N\"),\n",
    " ('IR-dim', 'lo'): (\"U<N\", \"D<D\"),\n",
    "    \n",
    " ('normal', 'hi'): (\"D<N\", \"U<N\"),\n",
    " ('doubly-ext', 'hi'): (\"D<E\", \"U<E\"),\n",
    " ('UV-ext', 'hi'): (\"D<E\", \"U<N\"),\n",
    " ('IR-ext', 'hi'): (\"D<N\", \"U<E\"),\n",
    " ('UV-dim', 'hi'): (\"D<D\", \"U<N\"),\n",
    " ('IR-dim', 'hi'): (\"D<N\", \"U<D\"),\n",
    "    \n",
    " ('normal', 'bp'): (\"O<N\", \"O<N\"),\n",
    " ('doubly-ext', 'bp'): (\"O<E\", \"O<E\"),\n",
    " ('UV-ext', 'bp'): (\"O<E\", \"O<N\"),\n",
    " ('IR-ext', 'bp'): (\"O<N\", \"O<E\"),\n",
    " ('UV-dim', 'bp'): (\"O<D\", \"O<N\"),\n",
    " ('IR-dim', 'bp'): (\"O<N\", \"O<D\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9372a72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn word/sentence into video sequencing of actions \n",
    "\n",
    "\n",
    "#lists will be [(action_description, length)] in order \n",
    "#action onset is at beginning of timelength and lasts for entire timelength \n",
    "#except for hand movements, which will only play for one beat and then return to home position (as filmed)\n",
    "class Video:\n",
    "    node_2 = None\n",
    "    node_3 = None\n",
    "    node_4 = None\n",
    "    node_5 = None\n",
    "    node_6 = None\n",
    "    node_7 = None\n",
    "    nodes = None\n",
    "    \n",
    "    morph_length = 6\n",
    "    \n",
    "    def __init__(self, encoding):\n",
    "        self.node_2 = {\"hand\":[], \"voice\":[], \"slap\": [], \"eyes\": []}\n",
    "        self.node_3 = {\"hand\":[], \"voice\":[], \"slap\": [], \"eyes\": []}\n",
    "        self.node_4 = {\"hand\":[], \"voice\":[], \"slap\": [], \"eyes\": []}\n",
    "        self.node_5 = {\"hand\":[], \"voice\":[], \"slap\": [], \"eyes\": []}\n",
    "        self.node_6 = {\"hand\":[], \"voice\":[], \"slap\": [], \"eyes\": []}\n",
    "        self.node_7 = {\"hand\":[], \"voice\":[], \"slap\": [], \"eyes\": []}\n",
    "        self.nodes = {\n",
    "            2: self.node_2, \n",
    "            3: self.node_3, \n",
    "            4: self.node_4, \n",
    "            5: self.node_5, \n",
    "            6: self.node_6, \n",
    "            7: self.node_7}\n",
    "        if len(encoding) == 6:\n",
    "            self.load_word(encoding)\n",
    "        elif len(encoding) == 21:\n",
    "            self.load_sentence(encoding)\n",
    "            \n",
    "    def load_word(self, word):\n",
    "        #print(\"loading word\", word)\n",
    "        for morpheme in word:\n",
    "            self.load_morpheme(morpheme)\n",
    "            \n",
    "        #fix hands ending thing at the end of words, here\n",
    "        self.fix_hands()\n",
    "        \n",
    "    def fix_hands(self):\n",
    "        for node in self.nodes:\n",
    "            hand_list = self.nodes[node]['hand']\n",
    "            #print(hand_list)\n",
    "            \n",
    "            if hand_list[-1][0] is None:\n",
    "                #check for all None\n",
    "                if all(x[0] is None for x in hand_list):\n",
    "                    home_movt = \"I<\"\n",
    "                    for i in range(len(hand_list)):\n",
    "                        hand_list[i] = (home_movt, self.morph_length / 2)\n",
    "                        \n",
    "                    print(hand_list)\n",
    "                    \n",
    "                else:\n",
    "                    i = -1 \n",
    "                    while hand_list[i][0] is None:\n",
    "                        i -= 1\n",
    "                    home_movt = hand_list[i][0][0] + \"<\"\n",
    "                    i+= 1\n",
    "                    while i <= -1:\n",
    "                        hand_list[i] = (home_movt, self.morph_length / 2) \n",
    "                        i+= 1\n",
    "                \n",
    "        \n",
    "    def load_morpheme(self, morph):\n",
    "        #print(\"loading morpheme\", morph)\n",
    "        \n",
    "        #do spectral first \n",
    "        self.load_spectral(morph.spectral)\n",
    "        \n",
    "        #then do sonic\n",
    "        if morph.sonic3 is not None:\n",
    "            self.load_sonic(morph.sonic1, 3)\n",
    "            self.load_sonic(morph.sonic2, 3)\n",
    "            self.load_sonic(morph.sonic3, 3)\n",
    "        elif morph.sonic2 is not None:\n",
    "            self.load_sonic(morph.sonic1, 2)\n",
    "            self.load_sonic(morph.sonic2, 2)\n",
    "        else:\n",
    "            self.load_sonic(morph.sonic1, 1)\n",
    "            \n",
    "        #then load gender\n",
    "        self.load_gender(morph.gender)\n",
    "        \n",
    "        #then load haptic\n",
    "        self.load_haptic(morph.haptic)\n",
    "        \n",
    "    def load_sonic(self, sonic, num_sonic):\n",
    "        #add whistle notes to hi/lo nodes \n",
    "        trans = sonic.trans\n",
    "        hi_node = trans[0]\n",
    "        lo_node = trans[1]\n",
    "        \n",
    "        hi_node_list = self.nodes[hi_node][\"voice\"]\n",
    "        lo_node_list = self.nodes[lo_node][\"voice\"]\n",
    "        \n",
    "        hi_node_list.append((str(trans), self.morph_length / num_sonic))\n",
    "        lo_node_list.append((str(trans), self.morph_length / num_sonic))\n",
    "        \n",
    "        #add humming notes to all other nodes (or HAH if free)\n",
    "        amp = sonic.amp\n",
    "        nodes = [2, 3, 4, 5, 6, 7]\n",
    "        nodes.remove(hi_node)\n",
    "        nodes.remove(lo_node)\n",
    "        \n",
    "        if amp == \"up\":\n",
    "            for node in nodes[0:3]: #lo note gets more representation (start from lo --> hi nodes)\n",
    "                node_list = self.nodes[node][\"voice\"]\n",
    "                node_list.append((str(lo_node), self.morph_length / num_sonic))\n",
    "            #then add hi note to remaining node\n",
    "            for node in nodes[-1:]:\n",
    "                node_list = self.nodes[node][\"voice\"]\n",
    "                node_list.append((str(hi_node), self.morph_length / num_sonic))\n",
    "                \n",
    "        elif amp == \"down\":\n",
    "            for node in nodes[0:1]: #lo note less representation (start from lo --> hi nodes)\n",
    "                node_list = self.nodes[node][\"voice\"]\n",
    "                node_list.append((str(lo_node), self.morph_length / num_sonic))\n",
    "            #then add hi note to other three nodes\n",
    "            for node in nodes[1:]:\n",
    "                node_list = self.nodes[node][\"voice\"]\n",
    "                node_list.append((str(hi_node), self.morph_length / num_sonic))\n",
    "                \n",
    "        elif amp == \"spike\":\n",
    "            for node in nodes[0:2]: #equal rep \n",
    "                node_list = self.nodes[node][\"voice\"]\n",
    "                node_list.append((str(lo_node), self.morph_length / num_sonic))\n",
    "            #then add hi note to other two\n",
    "            for node in nodes[2:]:\n",
    "                node_list = self.nodes[node][\"voice\"]\n",
    "                node_list.append((str(hi_node), self.morph_length / num_sonic))\n",
    "                \n",
    "        elif amp == \"free\": #add HAH to rest \n",
    "            for node in self.nodes:\n",
    "                if node != hi_node and node != lo_node:\n",
    "                    node_list = self.nodes[node][\"voice\"]\n",
    "                    node_list.append((\"HAH\", self.morph_length / num_sonic))\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def load_gender(self, gender):\n",
    "        #affects head turning / eyes opening \n",
    "        #if gender is present, open eyes & head forward\n",
    "        #AXE THE HEAD TURNING!!\n",
    "        for gen in gender:\n",
    "            self.nodes[gen][\"eyes\"].append((\"open\", self.morph_length))\n",
    "        \n",
    "        for node in self.nodes:\n",
    "            if node not in gender:\n",
    "                self.nodes[node][\"eyes\"].append((\"closed\", self.morph_length))\n",
    "        return\n",
    "    \n",
    "    def load_haptic(self, haptic):\n",
    "        #to schlap or not to schlap...that is the question\n",
    "        for hap in haptic:\n",
    "            self.nodes[hap][\"slap\"].append((\"slap\", self.morph_length))\n",
    "        \n",
    "        for node in self.nodes:\n",
    "            if node not in haptic:\n",
    "                self.nodes[node]['slap'].append((\"none\", self.morph_length))\n",
    "        return\n",
    "    \n",
    "    def load_spectral(self, spectral):     \n",
    "        #get spectral info \n",
    "        spectral_trans = spectral.trans \n",
    "        spectral_hi_node = spectral_trans[0]\n",
    "        spectral_lo_node = spectral_trans[1]\n",
    "        \n",
    "        #get hand movement sequences \n",
    "        width_filt = (spectral.width, spectral.filter)\n",
    "        hand_movts = hand_movt_mapping[width_filt]\n",
    "        \n",
    "        hi_movt = (hand_movts[0], self.morph_length/2)\n",
    "        hi_home = (hand_movts[0][0] + \"<\", self.morph_length/2)\n",
    "        \n",
    "        lo_home = (hand_movts[1][0] + \"<\", self.morph_length/2)\n",
    "        lo_movt = (hand_movts[1], self.morph_length/2)\n",
    "        \n",
    "        #for hi node:\n",
    "        hi_node_list = self.nodes[spectral_hi_node][\"hand\"]\n",
    "        #if necessary, change prev. hi_node Nones to hi_home nodes\n",
    "        if hi_node_list[-1:] != [] and hi_node_list[-1][0] == None:\n",
    "            i = len(hi_node_list) - 1\n",
    "            while i >= 0 and hi_node_list[i][0] == None:\n",
    "                hi_node_list[i] = hi_home\n",
    "                i -= 1\n",
    "        #then add movement and then home\n",
    "        hi_node_list.append(hi_movt)\n",
    "        hi_node_list.append(hi_home)\n",
    "    \n",
    "        \n",
    "        #for lo node:\n",
    "        #IF NOT ONE: \n",
    "        if spectral_lo_node != 1:\n",
    "            lo_node_list = self.nodes[spectral_lo_node][\"hand\"]\n",
    "            #change prev. lo node Nones to lo_home nodes \n",
    "            if lo_node_list[-1:] != [] and lo_node_list[-1][0] == None:\n",
    "                i = len(lo_node_list) - 1\n",
    "                while i >= 0 and lo_node_list[i][0] == None:\n",
    "                    lo_node_list[i] = lo_home\n",
    "                    i -= 1\n",
    "            #add home and then movement \n",
    "            lo_node_list.append(lo_home)\n",
    "            lo_node_list.append(lo_movt)\n",
    "            \n",
    "            #and then add placeholder to all other nodes \n",
    "            for node in self.nodes.keys():\n",
    "                if node != spectral_hi_node and node != spectral_lo_node:\n",
    "                    self.nodes[node][\"hand\"].append((None, self.morph_length/2))\n",
    "                    self.nodes[node][\"hand\"].append((None, self.morph_length/2))\n",
    "        \n",
    "        else: #if lo node is 1, then add home/movt to ALL OTHER NODES (and change prev. Nones)\n",
    "            for node in self.nodes.keys():\n",
    "                if node != spectral_hi_node:\n",
    "                    node_list = self.nodes[node][\"hand\"]\n",
    "                    #change prev Nones\n",
    "                    if node_list[-1:] != [] and node_list[-1][0] == None:\n",
    "                        i = len(node_list) - 1\n",
    "                        while i >= 0 and node_list[i][0] == None:\n",
    "                            node_list[i] = lo_home\n",
    "                            i -= 1\n",
    "                    node_list.append(lo_home)\n",
    "                    node_list.append(lo_movt)\n",
    "        \n",
    "        \n",
    "    def load_sentence(self, sentence):\n",
    "        for word in sentence:\n",
    "            self.load_word(word)\n",
    "        \n",
    "        \n",
    "    def __repr__(self):\n",
    "        string = \"\"\n",
    "        for node, sequence in self.nodes.items():\n",
    "            string += str(node) + \"\\n\"\n",
    "            string += \"hand: \" + str(sequence[\"hand\"]) + \"\\n\"\n",
    "            string += \"voice: \" + str(sequence[\"voice\"]) + \"\\n\"\n",
    "            string += \"eyes: \" + str(sequence[\"eyes\"]) + \"\\n\"\n",
    "            string += \"slap: \" + str(sequence[\"slap\"]) + \"\\n\"\n",
    "            \n",
    "        return string\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dd72f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn action sequence into clip sequencing\n",
    "def get_clip_sequencing(video):\n",
    "    node_2 = {\"hand\":[], \"voice\":[], \"slap\": [], \"eyes\": []}\n",
    "    node_3 = {\"hand\":[], \"voice\":[], \"slap\": [], \"eyes\": []}\n",
    "    node_4 = {\"hand\":[], \"voice\":[], \"slap\": [], \"eyes\": []}\n",
    "    node_5 = {\"hand\":[], \"voice\":[], \"slap\": [], \"eyes\": []}\n",
    "    node_6 = {\"hand\":[], \"voice\":[], \"slap\": [], \"eyes\": []}\n",
    "    node_7 = {\"hand\":[], \"voice\":[], \"slap\": [], \"eyes\": []}\n",
    "    clip_sequencing = {\n",
    "        2: node_2, \n",
    "        3: node_3, \n",
    "        4: node_4, \n",
    "        5: node_5, \n",
    "        6: node_6, \n",
    "        7: node_7}\n",
    "    \n",
    "    #don't need to do anything for sonic\n",
    "    for node in clip_sequencing:\n",
    "        clip_sequencing[node][\"voice\"] = video.nodes[node][\"voice\"]\n",
    "    \n",
    "    #for slap, just add a none at the end\n",
    "    for node in clip_sequencing:\n",
    "        clip_sequencing[node][\"slap\"] = video.nodes[node][\"slap\"]\n",
    "        clip_sequencing[node][\"slap\"].append((\"none\", 6))\n",
    "        \n",
    "    #for eyes\n",
    "    for node in clip_sequencing:\n",
    "        eyes_action_sequence = video.nodes[node][\"eyes\"]\n",
    "        for i in range(len(eyes_action_sequence)):\n",
    "            action = eyes_action_sequence[i]\n",
    "            \n",
    "            #print(action)\n",
    "            \n",
    "            if i == 0:\n",
    "                clip_sequencing[node][\"eyes\"].append((action[0][0], 6))\n",
    "                \n",
    "            else:\n",
    "                prev_action = clip_sequencing[node][\"eyes\"][-1]\n",
    "                #print(prev_action)\n",
    "                if prev_action[0][-1] == action[0][0]:\n",
    "                    clip_sequencing[node][\"eyes\"].append((action[0][0], 6))\n",
    "                else:\n",
    "                    clip_sequencing[node][\"eyes\"].append((prev_action[0][-1] + action[0][0], 6))\n",
    "                    \n",
    "        #then add the last bit\n",
    "        prev = clip_sequencing[node]['eyes'][-1][0][-1]\n",
    "        clip_sequencing[node]['eyes'].append((prev, 6))\n",
    "                \n",
    "            \n",
    "        \n",
    "    \n",
    "    #do spectral \n",
    "    for node in clip_sequencing:\n",
    "        spectral_action_sequence = video.nodes[node][\"hand\"]\n",
    "        for i in range(len(spectral_action_sequence)):\n",
    "            action = spectral_action_sequence[i]\n",
    "            #print(action)\n",
    "            #first one is a little different...\n",
    "            if i == 0:\n",
    "                #just add it - HOLD or movt will be ok \n",
    "                clip_sequencing[node][\"hand\"].append(action)\n",
    "            else:\n",
    "                prev_action = spectral_action_sequence[i-1]\n",
    "                curr_home = action[0][0]\n",
    "                prev_home = prev_action[0][0]\n",
    "                \n",
    "                if prev_home != curr_home:\n",
    "                    if len(prev_action[0]) == 2 and len(action[0]) == 2:\n",
    "                        clip_sequencing[node][\"hand\"].append((prev_action[0] + action[0], 3))\n",
    "                        #print(\"home to home\", prev_action[0], action[0])\n",
    "                        \n",
    "                    elif len(prev_action[0]) == 2 and len(action[0]) == 3:\n",
    "                        clip_sequencing[node][\"hand\"][-1] = (prev_action[0], 1.0)\n",
    "                        clip_sequencing[node][\"hand\"].append((prev_home + \"<\" + curr_home + \"<\", 2))\n",
    "                        clip_sequencing[node][\"hand\"].append((action[0], 3))\n",
    "                       # print(clip_sequencing[node][\"hand\"][-3:])\n",
    "                        \n",
    "                    elif len(prev_action[0]) == 3 and len(action[0]) == 2:\n",
    "                        clip_sequencing[node][\"hand\"].append((prev_home + \"<\" + action[0], 3))\n",
    "                        #print(\"movt to home\", prev_action[0], action[0])\n",
    "                        \n",
    "                    elif len(prev_action[0]) == 3 and len(action[0]) == 3:\n",
    "                        clip_sequencing[node][\"hand\"][-1] = (prev_action[0], 2.5)\n",
    "                        clip_sequencing[node][\"hand\"].append((prev_home + \"<\" + curr_home + \"<\", 1))\n",
    "                        clip_sequencing[node][\"hand\"].append((action[0], 2.5))\n",
    "                        #clip_sequencing[node][\"hand\"].append((\"MOVE TO MOVE THING\"))\n",
    "                        \n",
    "                       # print(\"movt to movt\", prev_action[0], action[0])\n",
    "                       # print(clip_sequencing[node][\"hand\"][-3:])\n",
    "                        \n",
    "                    \n",
    "                        #print(\"?>??????????\")\n",
    "                        #print(prev_action[0], action[0], i)\n",
    "                #print(prev_home, curr_home)\n",
    "                \n",
    "                else:\n",
    "                    clip_sequencing[node][\"hand\"].append(action)\n",
    "                    \n",
    "        #then add the last bit, to end with 2sec extra\n",
    "        prev_home = clip_sequencing[node][\"hand\"][-1][0][0]\n",
    "        clip_sequencing[node][\"hand\"].append((prev_home + \"<\", 3.0))\n",
    "            \n",
    "        #print()\n",
    "    return clip_sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1814ebb-b12a-4a35-b411-82f62329f928",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence =  generate_random_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "697e3f14-87db-4a2e-87ff-919ab56cbb80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spectral: (6, 1) UV-ext tri\n",
       "sonic1: (5, 2) down\n",
       "sonic2: (6, 3) spike\n",
       "sonic3: (6, 2) up\n",
       "gender: [np.int64(7), np.int64(2), np.int64(6), np.int64(4)]\n",
       "haptic: [np.int64(5), np.int64(3), np.int64(4), np.int64(2)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5bef6b2-1faa-4b5e-a45b-c8c638cdb8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../HE-DEMS sentence encodings (scores)/random_sentence_1.json') as f:\n",
    "    rand_1 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dbffc61-f2d5-4020-9e37-cbbb6df8f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vid = Video(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f06b4c48-4caa-4b54-a748-710430f35187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_vid.node_2['slap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49071d51-f782-40cb-a434-2f17ce0863a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('slap', 6)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_vid.node_2['slap'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84886f4e-e626-431e-89b9-b5a82b073ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_clip_sequence = get_clip_sequencing(sentence_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d37d7b6-e68f-4d79-badf-866043effe89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_clip_sequence[2]['hand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e77878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#first, generate random word or sentence\n",
    "word = generate_random_word()\n",
    "sentence = generate_random_sentence()\n",
    "\n",
    "#then, get video action sequence from those\n",
    "word_vid = Video(word)\n",
    "sentence_vid = Video(sentence)\n",
    "\n",
    "#then, get clip sequencing from those\n",
    "\n",
    "word_clip_sequencing = get_clip_sequencing(word_vid)\n",
    "sentence_clip_sequencing = get_clip_sequencing(sentence_vid)\n",
    "\n",
    "#then, save sentence sequencing to json\n",
    "import json\n",
    "with open(\"sentence-encoding.json\", \"w\") as file:\n",
    "    json.dump(sentence_clip_sequencing, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1bc704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load file from json\n",
    "import json\n",
    "with open(\"embodied performance/RANDOM-SPEECH/sentence-encoding.json\", \"r\") as file:\n",
    "    sentence_encoding = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15f51355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, concatenate_videoclips, concatenate_audioclips, AudioFileClip\n",
    "import os\n",
    "\n",
    "#create video clips from sequencing info\n",
    "node_2_folderpath = \"embodied performance/1. marquise/EDITED/\"\n",
    "node_3_folderpath = \"embodied performance/2. putri/EDITED/\"\n",
    "node_4_folderpath = \"embodied performance/3. rachel/EDITED/\"\n",
    "node_5_folderpath = \"embodied performance/4. lacie/EDITED/\"\n",
    "node_6_folderpath = \"embodied performance/5. reshma/EDITED/\"\n",
    "node_7_folderpath = \"embodied performance/6. nancy/EDITED/\"\n",
    "node_folders = {\n",
    "    2: node_2_folderpath,\n",
    "    3: node_3_folderpath,\n",
    "    4: node_4_folderpath,\n",
    "    5: node_5_folderpath,\n",
    "    6: node_6_folderpath,\n",
    "    7: node_7_folderpath\n",
    "}\n",
    "\n",
    "SHORT_start = \"00:00:00.08\"\n",
    "SHORT_end = \"00:00:01.04\"\n",
    "\n",
    "start_2 = 0\n",
    "end_2 = 1.5\n",
    "\n",
    "start_25 = 0\n",
    "end_25 = 1.875\n",
    "\n",
    "def make_video_clips(sequencing, name):\n",
    "    #first, make folder to store everything\n",
    "    #print(\"HELOWERIJ WEO\")\n",
    "    store_folder = \"embodied performance/RANDOM-SPEECH/\" + name + \"/\"\n",
    "    if not os.path.exists(store_folder):\n",
    "        os.mkdir(store_folder)\n",
    "    \n",
    "    #go node by node \n",
    "    for node in sequencing:\n",
    "        #print(node)\n",
    "        info = sequencing[str(node)]\n",
    "        #print(info)\n",
    "        hand_info = info[\"hand\"]\n",
    "        eyes_info = info['eyes']\n",
    "        slap_info = info['slap']\n",
    "        voice_info = info['voice']\n",
    "        \n",
    "        #print(slap_info)\n",
    "        \n",
    "        #only do marquise for now lol \n",
    "        if int(node) == 2:\n",
    "        #do hands\n",
    "            make_hands_video(node, name, store_folder, hand_info)\n",
    "        #then eyes\n",
    "            #make_eyes_video(node, name, store_folder, eyes_info)\n",
    "        #then slap\n",
    "            #make_slap_video(int(node), name, store_folder, slap_info)\n",
    "        #then voice \n",
    "            #make_voice_video(node, name, store_folder, voice_info)\n",
    "        \n",
    "def make_hands_video(node, name, store_folder, hand_info):\n",
    "    \n",
    "    #where to look for clips\n",
    "    source_folder = node_folders[int(node)] + \"HANDS/\"\n",
    "    print(source_folder)\n",
    "    #where to put final concatenated video\n",
    "    hands_clip_filename = store_folder + str(node) + \"-hands\"\n",
    "    #where to store clips in order\n",
    "    single_clip_list = []\n",
    "    concatenated_clip_list = []\n",
    "    \n",
    "    total_length = 0\n",
    "    i = 0\n",
    "    \n",
    "    #iterate through info\n",
    "    for info in hand_info:\n",
    "        #get filename and length\n",
    "        clip_filename = info[0].replace(\"<\", \"-\") + \".mp4\"\n",
    "        print(info[0], clip_filename)\n",
    "        clip_filename = source_folder + clip_filename\n",
    "        clip_length = info[1]\n",
    "        \n",
    "        #make clip based on length\n",
    "        if clip_length == 3.0 or clip_length == 3: \n",
    "            clip = VideoFileClip(clip_filename)\n",
    "        elif clip_length == 2.5:\n",
    "            clip = VideoFileClip(clip_filename).subclip(start_25, end_25)\n",
    "        elif clip_length == 2.0 or clip_length == 2:\n",
    "            clip = VideoFileClip(clip_filename).subclip(start_2, end_2)\n",
    "        elif clip_length == 1.0 or clip_length == 1:\n",
    "            clip = VideoFileClip(clip_filename).subclip(SHORT_start, SHORT_end)\n",
    "            \n",
    "        else:\n",
    "            print(\"heello????)\")\n",
    "           \n",
    "        #save clip to list \n",
    "        single_clip_list.append(clip)\n",
    "        total_length += clip_length\n",
    "        \n",
    "        print(total_length)\n",
    "        \n",
    "        if total_length == 36 or total_length == 36.0 or total_length == 72.0 or total_length == 144.0:\n",
    "            print(\"consolidating morpheme\")\n",
    "            if total_length == 36.0:\n",
    "                concatenated_clip = concatenate_videoclips(single_clip_list)\n",
    "                concatenated_clip_filename = hands_clip_filename + \"-\" + str(i) + \".mp4\"\n",
    "                concatenated_clip.write_videofile(concatenated_clip_filename)\n",
    "                print(concatenated_clip_filename)\n",
    "                concatenated_clip_list.append(concatenated_clip_filename)\n",
    "                i += 1\n",
    "                \n",
    "            elif total_length == 72.0:\n",
    "                concatenated_clip = concatenate_videoclips(single_clip_list)\n",
    "                concat_1 = concatenated_clip.subclip(0, 27)\n",
    "                concat_1_filename = hands_clip_filename + \"-\" + str(i) + \".mp4\"\n",
    "                i += 1\n",
    "                concat_2 = concatenated_clip.subclip(27, 54)\n",
    "                concat_2_filename = hands_clip_filename + \"-\" + str(i) + \".mp4\"\n",
    "                i += 1\n",
    "                concat_1.write_videofile(concat_1_filename)\n",
    "                concatenated_clip_list.append(concat_1_filename)\n",
    "                concat_2.write_videofile(concat_2_filename)\n",
    "                concatenated_clip_list.append(concat_2_filename)\n",
    "                \n",
    "                \n",
    "            elif total_length == 144.0:\n",
    "                concatenated_clip = concatenate_videoclips(single_clip_list)\n",
    "                concat_1 = concatenated_clip.subclip(0, 27)\n",
    "                concat_1_filename = hands_clip_filename + \"-\" + str(i) + \".mp4\"\n",
    "                i += 1\n",
    "                concat_2 = concatenated_clip.subclip(27, 54)\n",
    "                concat_2_filename = hands_clip_filename + \"-\" + str(i) + \".mp4\"\n",
    "                i += 1\n",
    "                concat_3 = concatenated_clip.subclip(54, 81)\n",
    "                concat_3_filename = hands_clip_filename + \"-\" + str(i) + \".mp4\"\n",
    "                i += 1\n",
    "                concat_4 = concatenated_clip.subclip(81, 108)\n",
    "                concat_4_filename = hands_clip_filename + \"-\" + str(i) + \".mp4\"\n",
    "                i += 1\n",
    "                concat_1.write_videofile(concat_1_filename)\n",
    "                concatenated_clip_list.append(concat_1_filename)\n",
    "                concat_2.write_videofile(concat_2_filename)\n",
    "                concatenated_clip_list.append(concat_2_filename)\n",
    "                concat_3.write_videofile(concat_3_filename)\n",
    "                concatenated_clip_list.append(concat_3_filename)\n",
    "                concat_4.write_videofile(concat_4_filename)\n",
    "                concatenated_clip_list.append(concat_4_filename)\n",
    "                \n",
    "                \n",
    "                \n",
    "            for clip in single_clip_list:\n",
    "                clip.close()\n",
    "                \n",
    "            single_clip_list = []\n",
    "            total_length = 0\n",
    "            \n",
    "    \n",
    "    #should be one single clip left .... \n",
    "    print(len(single_clip_list))\n",
    "    print(len(concatenated_clip_list))\n",
    "    \n",
    "    all_clips = [VideoFileClip(clip).subclip(0, 27) for clip in concatenated_clip_list]\n",
    "    all_clips += single_clip_list\n",
    "    \n",
    "    hands_clip = concatenate_videoclips(all_clips)\n",
    "    hands_clip.write_videofile(hands_clip_filename + \".mp4\")\n",
    "    \n",
    "    \n",
    "    return\n",
    "    \n",
    "               \n",
    "def make_eyes_video(node, name, store_folder, eyes_info):\n",
    "    \n",
    "    #where to look for clips\n",
    "    source_folder = node_folders[int(node)] + \"EYES/\"\n",
    "    print(source_folder)\n",
    "    #where to put final concatenated video\n",
    "    eyes_clip_filename = store_folder + str(node) + \"-eyes\"\n",
    "    #where to store clips in order\n",
    "    single_clip_list = []\n",
    "    concatenated_clip_list = []\n",
    "    \n",
    "    total_length = 0\n",
    "    i = 0\n",
    "    \n",
    "    for info in eyes_info:\n",
    "        clip_filename = info[0] + \".mp4\"\n",
    "        print(info[0], clip_filename)\n",
    "        clip_filename = source_folder + clip_filename\n",
    "        clip = VideoFileClip(clip_filename)\n",
    "        single_clip_list.append(clip)\n",
    "        total_length += 6\n",
    "        \n",
    "        if total_length == 36:\n",
    "            print(\"consolidating morpheme\")\n",
    "            concatenated_clip = concatenate_videoclips(single_clip_list)\n",
    "            concatenated_clip_filename = eyes_clip_filename + \"-\" + str(i) + \".mp4\"\n",
    "            concatenated_clip.write_videofile(concatenated_clip_filename)\n",
    "            print(concatenated_clip_filename)\n",
    "            concatenated_clip_list.append(concatenated_clip_filename)\n",
    "                \n",
    "            for clip in single_clip_list:\n",
    "                clip.close()\n",
    "                \n",
    "            single_clip_list = []\n",
    "            total_length = 0\n",
    "            i += 1\n",
    "        \n",
    "    #should be one single clip left .... \n",
    "    print(len(single_clip_list))\n",
    "    print(len(concatenated_clip_list))\n",
    "    \n",
    "    all_clips = [VideoFileClip(clip).subclip(0, 27) for clip in concatenated_clip_list]\n",
    "    all_clips += single_clip_list\n",
    "    \n",
    "    eyes_clip = concatenate_videoclips(all_clips)\n",
    "    eyes_clip.write_videofile(eyes_clip_filename + \".mp4\")\n",
    "        \n",
    "    return\n",
    "    \n",
    "def make_slap_video(node, name, store_folder, slap_info):\n",
    "    \n",
    "    \"\"\"\n",
    "    MAKE SLAP TRACK AS WELL!!!!!!\n",
    "    \"\"\"\n",
    "    \n",
    "    #where to look for clips\n",
    "    source_folder = node_folders[int(node)] + \"SLAP/\"\n",
    "    print(source_folder)\n",
    "    #where to put final concatenated video\n",
    "    slap_clip_filename = store_folder + str(node) + \"-slap\"\n",
    "    slap_audio_filename = slap_clip_filename + \"-audio\"\n",
    "    #where to store clips in order\n",
    "    clip_list = []\n",
    "    single_clip_list = []\n",
    "    concatenated_clip_list = []\n",
    "    \n",
    "    single_audio_list = []\n",
    "    concat_audio_list = []\n",
    "    slap_source_folder = \"embodied performance/SLAP/\"\n",
    "    total_length = 0\n",
    "    i = 0\n",
    "    \n",
    "    \n",
    "    for info in slap_info:\n",
    "        clip_filename = info[0] + \".mp4\"\n",
    "        print(info[0], clip_filename)\n",
    "        clip_filename = source_folder + clip_filename\n",
    "        clip = VideoFileClip(clip_filename)\n",
    "        single_clip_list.append(clip)\n",
    "        \n",
    "        if info[0] == \"slap\":\n",
    "            audio_filename = slap_source_folder + info[0] + \"-0\" + str(np.random.randint(8)+1) + \".wav\"\n",
    "            print(os.path.exists(audio_filename))\n",
    "        else:\n",
    "            audio_filename = slap_source_folder + \"none.wav\"\n",
    "            \n",
    "        audio = AudioFileClip(audio_filename)\n",
    "        single_audio_list.append(audio)\n",
    "            \n",
    "        total_length += 6\n",
    "        \n",
    "        if total_length == 36:\n",
    "            print(\"consolidating morpheme\")\n",
    "            concatenated_clip = concatenate_videoclips(single_clip_list)\n",
    "            concatenated_clip_filename = slap_clip_filename + \"-\" + str(i) + \".mp4\"\n",
    "            concatenated_clip.write_videofile(concatenated_clip_filename)\n",
    "            print(concatenated_clip_filename)\n",
    "            concatenated_clip_list.append(concatenated_clip_filename)\n",
    "                \n",
    "            for clip in single_clip_list:\n",
    "                clip.close()\n",
    "                \n",
    "            single_clip_list = []\n",
    "            \n",
    "            concat_audio = concatenate_audioclips(single_audio_list)\n",
    "            concat_audio_filename = slap_audio_filename + \"-\" + str(i) + \".wav\"\n",
    "            concat_audio.write_audiofile(concat_audio_filename)\n",
    "            print(concat_audio_filename)\n",
    "            concat_audio_list.append(concat_audio_filename)\n",
    "            \n",
    "            for clip in single_audio_list:\n",
    "                clip.close()\n",
    "                \n",
    "            single_audio_list = []\n",
    "            \n",
    "            total_length = 0\n",
    "            i += 1\n",
    "        \n",
    "    #should be one single clip left .... \n",
    "    print(len(single_clip_list))\n",
    "    print(len(concatenated_clip_list))\n",
    "    \n",
    "    print(len(single_audio_list))\n",
    "    print(len(concat_audio_list))\n",
    "    \n",
    "    all_clips = [VideoFileClip(clip).subclip(0, 27) for clip in concatenated_clip_list]\n",
    "    all_clips += single_clip_list\n",
    "    \n",
    "    slap_clip = concatenate_videoclips(all_clips)\n",
    "    slap_clip.write_videofile(slap_clip_filename + \".mp4\")\n",
    "    \n",
    "    all_audio = [AudioFileClip(clip).subclip(0, 27) for clip in concat_audio_list]\n",
    "    all_audio += single_audio_list\n",
    "    \n",
    "    slap_audio = concatenate_audioclips(all_audio)\n",
    "    slap_audio.write_audiofile(slap_audio_filename + \".wav\")\n",
    "    \n",
    "    return\n",
    "    \n",
    "def make_voice_video(node, name, store_folder, voice_info):\n",
    "    \n",
    "    #where to look for clips\n",
    "    source_folder = node_folders[int(node)] + \"VOICE/\"\n",
    "    print(source_folder)\n",
    "    #where to put final concatenated video\n",
    "    voice_clip_filename = store_folder + str(node) + \"-voice\"\n",
    "    #where to store clips in order\n",
    "    single_clip_list = []\n",
    "    concatenated_clip_list = []\n",
    "    total_length = 0\n",
    "    i = 0\n",
    "    \n",
    "    for info in voice_info:\n",
    "        noise = info[0]\n",
    "        length = info[1] \n",
    "        \n",
    "        if len(noise) == 1: #hum \n",
    "            clip_filename = noise\n",
    "            if length == 6.0:\n",
    "                clip_filename += \"-01.wav\"\n",
    "            elif length == 3.0:\n",
    "                clip_filename += \"-02.wav\"\n",
    "            elif length == 2.0:\n",
    "                clip_filename += \"-03.wav\"\n",
    "                \n",
    "        elif len(noise) == 3: #HAH\n",
    "            clip_filename = noise\n",
    "            if length == 6.0: \n",
    "                clip_filename += \"-6\"\n",
    "            elif length == 3.0:\n",
    "                clip_filename += \"-3\"\n",
    "            elif length == 2.0:\n",
    "                clip_filename += \"-2\"\n",
    "            clip_filename += \"-0\" + str(np.random.randint(3)+1)+\".wav\"\n",
    "            \n",
    "        elif len(noise) == 6:\n",
    "            clip_filename = noise.replace(\",\", \"\")\n",
    "            if length == 6.0:\n",
    "                clip_filename += \"-01.wav\"\n",
    "            elif length == 3.0:\n",
    "                clip_filename += \"-02.wav\"\n",
    "            elif length == 2.0:\n",
    "                clip_filename += \"-03.wav\"\n",
    "        print(noise, length, clip_filename)\n",
    "        \n",
    "        clip_filename = source_folder + clip_filename\n",
    "        clip = AudioFileClip(clip_filename)\n",
    "        single_clip_list.append(clip)\n",
    "        \n",
    "        total_length += length\n",
    "        \n",
    "        print(total_length)\n",
    "        \n",
    "        \n",
    "        if total_length == 36.0:\n",
    "            print(\"consolidating morpheme\")\n",
    "            concatenated_clip = concatenate_audioclips(single_clip_list)\n",
    "            concatenated_clip_filename = voice_clip_filename + \"-\" + str(i) + \".wav\"\n",
    "            concatenated_clip.write_audiofile(concatenated_clip_filename)\n",
    "            print(concatenated_clip_filename)\n",
    "            concatenated_clip_list.append(concatenated_clip_filename)\n",
    "                \n",
    "            for clip in single_clip_list:\n",
    "                clip.close()\n",
    "                \n",
    "            single_clip_list = []\n",
    "            total_length = 0\n",
    "            i += 1\n",
    "        \n",
    "    print(len(single_clip_list))\n",
    "    print(len(concatenated_clip_list))\n",
    "    \n",
    "    all_clips = [AudioFileClip(clip).subclip(0, 27) for clip in concatenated_clip_list]\n",
    "    \n",
    "    voice_clip = concatenate_audioclips(all_clips)\n",
    "    voice_clip.write_audiofile(voice_clip_filename + \".mp3\")\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cdf45e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embodied performance/1. marquise/EDITED/HANDS/\n",
      "U< U-.mp4\n",
      "3.0\n",
      "U<D U-D.mp4\n",
      "6.0\n",
      "U<O< U-O-.mp4\n",
      "9.0\n",
      "O< O-.mp4\n",
      "12.0\n",
      "O< O-.mp4\n",
      "15.0\n",
      "O< O-.mp4\n",
      "18.0\n",
      "O< O-.mp4\n",
      "21.0\n",
      "O<E O-E.mp4\n",
      "24.0\n",
      "O<U< O-U-.mp4\n",
      "27.0\n",
      "U<N U-N.mp4\n",
      "30.0\n",
      "U< U-.mp4\n",
      "33.0\n",
      "U< U-.mp4\n",
      "34.0\n",
      "U<O< U-O-.mp4\n",
      "36.0\n",
      "consolidating morpheme\n",
      "Moviepy - Building video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-0.mp4.\n",
      "MoviePy - Writing audio in 2-hands-0TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-0.mp4\n",
      "embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-0.mp4\n",
      "O<N O-N.mp4\n",
      "3\n",
      "O< O-.mp4\n",
      "6.0\n",
      "O< O-.mp4\n",
      "9.0\n",
      "O<E O-E.mp4\n",
      "12.0\n",
      "O<U< O-U-.mp4\n",
      "15.0\n",
      "U< U-.mp4\n",
      "18.0\n",
      "U< U-.mp4\n",
      "21.0\n",
      "U< U-.mp4\n",
      "24.0\n",
      "U< U-.mp4\n",
      "27.0\n",
      "U<E U-E.mp4\n",
      "30.0\n",
      "U< U-.mp4\n",
      "33.0\n",
      "U<E U-E.mp4\n",
      "36.0\n",
      "consolidating morpheme\n",
      "Moviepy - Building video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-1.mp4.\n",
      "MoviePy - Writing audio in 2-hands-1TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-1.mp4\n",
      "embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-1.mp4\n",
      "U<D< U-D-.mp4\n",
      "3\n",
      "D< D-.mp4\n",
      "6.0\n",
      "D< D-.mp4\n",
      "9.0\n",
      "D< D-.mp4\n",
      "12.0\n",
      "D< D-.mp4\n",
      "15.0\n",
      "D< D-.mp4\n",
      "18.0\n",
      "D< D-.mp4\n",
      "21.0\n",
      "D<D D-D.mp4\n",
      "24.0\n",
      "D<U< D-U-.mp4\n",
      "27.0\n",
      "U< U-.mp4\n",
      "30.0\n",
      "U< U-.mp4\n",
      "33.0\n",
      "U<D U-D.mp4\n",
      "36.0\n",
      "consolidating morpheme\n",
      "Moviepy - Building video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-2.mp4.\n",
      "MoviePy - Writing audio in 2-hands-2TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-2.mp4\n",
      "embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-2.mp4\n",
      "U< U-.mp4\n",
      "3.0\n",
      "U< U-.mp4\n",
      "6.0\n",
      "U< U-.mp4\n",
      "9.0\n",
      "U< U-.mp4\n",
      "12.0\n",
      "U< U-.mp4\n",
      "15.0\n",
      "U<N U-N.mp4\n",
      "18.0\n",
      "U< U-.mp4\n",
      "21.0\n",
      "U<N U-N.mp4\n",
      "24.0\n",
      "U< U-.mp4\n",
      "27.0\n",
      "U< U-.mp4\n",
      "30.0\n",
      "U< U-.mp4\n",
      "33.0\n",
      "U< U-.mp4\n",
      "36.0\n",
      "consolidating morpheme\n",
      "Moviepy - Building video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-3.mp4.\n",
      "MoviePy - Writing audio in 2-hands-3TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-3.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-3.mp4\n",
      "embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-3.mp4\n",
      "U<O< U-O-.mp4\n",
      "3\n",
      "O< O-.mp4\n",
      "6.0\n",
      "O< O-.mp4\n",
      "9.0\n",
      "O<E O-E.mp4\n",
      "12.0\n",
      "O< O-.mp4\n",
      "15.0\n",
      "O<E O-E.mp4\n",
      "18.0\n",
      "O<U< O-U-.mp4\n",
      "21.0\n",
      "U<D U-D.mp4\n",
      "24.0\n",
      "U<I< U-I-.mp4\n",
      "27.0\n",
      "I< I-.mp4\n",
      "30.0\n",
      "I< I-.mp4\n",
      "33.0\n",
      "I<E I-E.mp4\n",
      "36.0\n",
      "consolidating morpheme\n",
      "Moviepy - Building video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-4.mp4.\n",
      "MoviePy - Writing audio in 2-hands-4TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-4.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-4.mp4\n",
      "embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-4.mp4\n",
      "I<D< I-D-.mp4\n",
      "3\n",
      "D< D-.mp4\n",
      "6.0\n",
      "D< D-.mp4\n",
      "9.0\n",
      "D< D-.mp4\n",
      "12.0\n",
      "D< D-.mp4\n",
      "15.0\n",
      "D< D-.mp4\n",
      "18.0\n",
      "D< D-.mp4\n",
      "21.0\n",
      "D<D D-D.mp4\n",
      "24.0\n",
      "D<I< D-I-.mp4\n",
      "27.0\n",
      "I<N I-N.mp4\n",
      "30.0\n",
      "I< I-.mp4\n",
      "33.0\n",
      "I< I-.mp4\n",
      "36.0\n",
      "consolidating morpheme\n",
      "Moviepy - Building video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-5.mp4.\n",
      "MoviePy - Writing audio in 2-hands-5TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-5.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-5.mp4\n",
      "embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-5.mp4\n",
      "I<D< I-D-.mp4\n",
      "3\n",
      "D< D-.mp4\n",
      "6.0\n",
      "D< D-.mp4\n",
      "9.0\n",
      "D< D-.mp4\n",
      "12.0\n",
      "D< D-.mp4\n",
      "15.0\n",
      "D<N D-N.mp4\n",
      "18.0\n",
      "D<I< D-I-.mp4\n",
      "21.0\n",
      "I< I-.mp4\n",
      "24.0\n",
      "I< I-.mp4\n",
      "27.0\n",
      "I< I-.mp4\n",
      "30.0\n",
      "I< I-.mp4\n",
      "33.0\n",
      "I<N I-N.mp4\n",
      "36.0\n",
      "consolidating morpheme\n",
      "Moviepy - Building video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-6.mp4.\n",
      "MoviePy - Writing audio in 2-hands-6TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-6.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-6.mp4\n",
      "embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-6.mp4\n",
      "I< I-.mp4\n",
      "3.0\n",
      "I< I-.mp4\n",
      "6.0\n",
      "I< I-.mp4\n",
      "9.0\n",
      "I< I-.mp4\n",
      "12.0\n",
      "I< I-.mp4\n",
      "15.0\n",
      "I< I-.mp4\n",
      "18.0\n",
      "I< I-.mp4\n",
      "21.0\n",
      "I< I-.mp4\n",
      "24.0\n",
      "I< I-.mp4\n",
      "27.0\n",
      "I<N I-N.mp4\n",
      "30.0\n",
      "I< I-.mp4\n",
      "33.0\n",
      "I< I-.mp4\n",
      "36.0\n",
      "consolidating morpheme\n",
      "Moviepy - Building video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-7.mp4.\n",
      "MoviePy - Writing audio in 2-hands-7TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-7.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-7.mp4\n",
      "embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-7.mp4\n",
      "I<U< I-U-.mp4\n",
      "3\n",
      "U<N U-N.mp4\n",
      "6.0\n",
      "U<I< U-I-.mp4\n",
      "9.0\n",
      "I< I-.mp4\n",
      "12.0\n",
      "I< I-.mp4\n",
      "15.0\n",
      "I<N I-N.mp4\n",
      "18.0\n",
      "I<O< I-O-.mp4\n",
      "21.0\n",
      "O<N O-N.mp4\n",
      "24.0\n",
      "O<U< O-U-.mp4\n",
      "27.0\n",
      "U<E U-E.mp4\n",
      "30.0\n",
      "U< U-.mp4\n",
      "33.0\n",
      "U< U-.mp4\n",
      "36.0\n",
      "consolidating morpheme\n",
      "Moviepy - Building video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-8.mp4.\n",
      "MoviePy - Writing audio in 2-hands-8TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-8.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-8.mp4\n",
      "embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-8.mp4\n",
      "U<O< U-O-.mp4\n",
      "3\n",
      "O<D O-D.mp4\n",
      "6.0\n",
      "O<D< O-D-.mp4\n",
      "9.0\n",
      "D<N D-N.mp4\n",
      "12.0\n",
      "D<U< D-U-.mp4\n",
      "15.0\n",
      "U<N U-N.mp4\n",
      "18.0\n",
      "U< U-.mp4\n",
      "21.0\n",
      "U< U-.mp4\n",
      "24.0\n",
      "U< U-.mp4\n",
      "27.0\n",
      "U< U-.mp4\n",
      "30.0\n",
      "U< U-.mp4\n",
      "33.0\n",
      "U< U-.mp4\n",
      "36.0\n",
      "consolidating morpheme\n",
      "Moviepy - Building video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-9.mp4.\n",
      "MoviePy - Writing audio in 2-hands-9TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-9.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-9.mp4\n",
      "embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-9.mp4\n",
      "U< U-.mp4\n",
      "3.0\n",
      "U< U-.mp4\n",
      "6.0\n",
      "U< U-.mp4\n",
      "9.0\n",
      "U<E U-E.mp4\n",
      "12.0\n",
      "U<I< U-I-.mp4\n",
      "15.0\n",
      "I<E I-E.mp4\n",
      "18.0\n",
      "I< I-.mp4\n",
      "21.0\n",
      "I< I-.mp4\n",
      "24.0\n",
      "I< I-.mp4\n",
      "27.0\n",
      "I< I-.mp4\n",
      "30.0\n",
      "I< I-.mp4\n",
      "33.0\n",
      "I< I-.mp4\n",
      "36.0\n",
      "consolidating morpheme\n",
      "Moviepy - Building video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-10.mp4.\n",
      "MoviePy - Writing audio in 2-hands-10TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-10.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-10.mp4\n",
      "embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-10.mp4\n",
      "I<U< I-U-.mp4\n",
      "3\n",
      "U<D U-D.mp4\n",
      "6.0\n",
      "U< U-.mp4\n",
      "9.0\n",
      "U< U-.mp4\n",
      "12.0\n",
      "U< U-.mp4\n",
      "15.0\n",
      "U<E U-E.mp4\n",
      "18.0\n",
      "U<D< U-D-.mp4\n",
      "21.0\n",
      "D<D D-D.mp4\n",
      "24.0\n",
      "D<I< D-I-.mp4\n",
      "27.0\n",
      "I<N I-N.mp4\n",
      "30.0\n",
      "I< I-.mp4\n",
      "33.0\n",
      "I< I-.mp4\n",
      "36.0\n",
      "consolidating morpheme\n",
      "Moviepy - Building video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-11.mp4.\n",
      "MoviePy - Writing audio in 2-hands-11TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-11.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-11.mp4\n",
      "embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-11.mp4\n",
      "I<D< I-D-.mp4\n",
      "3\n",
      "D<D D-D.mp4\n",
      "6.0\n",
      "D<I< D-I-.mp4\n",
      "9.0\n",
      "I<D I-D.mp4\n",
      "12.0\n",
      "I<U< I-U-.mp4\n",
      "15.0\n",
      "U< U-.mp4\n",
      "18.0\n",
      "U< U-.mp4\n",
      "21.0\n",
      "U< U-.mp4\n",
      "24.0\n",
      "U< U-.mp4\n",
      "27.0\n",
      "U< U-.mp4\n",
      "30.0\n",
      "U< U-.mp4\n",
      "33.0\n",
      "U<E U-E.mp4\n",
      "36.0\n",
      "consolidating morpheme\n",
      "Moviepy - Building video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-12.mp4.\n",
      "MoviePy - Writing audio in 2-hands-12TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-12.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-12.mp4\n",
      "embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-12.mp4\n",
      "U<D< U-D-.mp4\n",
      "3\n",
      "D< D-.mp4\n",
      "6.0\n",
      "D< D-.mp4\n",
      "9.0\n",
      "D<D D-D.mp4\n",
      "12.0\n",
      "D<U< D-U-.mp4\n",
      "15.0\n",
      "U< U-.mp4\n",
      "18.0\n",
      "U< U-.mp4\n",
      "21.0\n",
      "U< U-.mp4\n",
      "24.0\n",
      "U< U-.mp4\n",
      "27.0\n",
      "U<E U-E.mp4\n",
      "30.0\n",
      "U< U-.mp4\n",
      "33.0\n",
      "U<E U-E.mp4\n",
      "35.5\n",
      "U<D< U-D-.mp4\n",
      "36.5\n",
      "D<E D-E.mp4\n",
      "39.0\n",
      "D< D-.mp4\n",
      "40.0\n",
      "D<O< D-O-.mp4\n",
      "42.0\n",
      "O<E O-E.mp4\n",
      "45.0\n",
      "O< O-.mp4\n",
      "48.0\n",
      "O< O-.mp4\n",
      "51.0\n",
      "O<N O-N.mp4\n",
      "54.0\n",
      "O<D< O-D-.mp4\n",
      "57.0\n",
      "D<N D-N.mp4\n",
      "60.0\n",
      "D<I< D-I-.mp4\n",
      "63.0\n",
      "I< I-.mp4\n",
      "66.0\n",
      "I< I-.mp4\n",
      "69.0\n",
      "I<N I-N.mp4\n",
      "72.0\n",
      "consolidating morpheme\n",
      "Moviepy - Building video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-13.mp4.\n",
      "MoviePy - Writing audio in 2-hands-13TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-13.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-13.mp4\n",
      "Moviepy - Building video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-14.mp4.\n",
      "MoviePy - Writing audio in 2-hands-14TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-14.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-14.mp4\n",
      "I<O< I-O-.mp4\n",
      "3\n",
      "O< O-.mp4\n",
      "6.0\n",
      "O< O-.mp4\n",
      "9.0\n",
      "O< O-.mp4\n",
      "12.0\n",
      "O< O-.mp4\n",
      "15.0\n",
      "O<N O-N.mp4\n",
      "18.0\n",
      "O<U< O-U-.mp4\n",
      "21.0\n",
      "U< U-.mp4\n",
      "24.0\n",
      "U< U-.mp4\n",
      "27.0\n",
      "U<N U-N.mp4\n",
      "30.0\n",
      "U<D< U-D-.mp4\n",
      "33.0\n",
      "D<N D-N.mp4\n",
      "36.0\n",
      "consolidating morpheme\n",
      "Moviepy - Building video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-15.mp4.\n",
      "MoviePy - Writing audio in 2-hands-15TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-15.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-15.mp4\n",
      "embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-15.mp4\n",
      "D<O< D-O-.mp4\n",
      "3\n",
      "O< O-.mp4\n",
      "6.0\n",
      "O< O-.mp4\n",
      "9.0\n",
      "O< O-.mp4\n",
      "12.0\n",
      "O< O-.mp4\n",
      "15.0\n",
      "O<E O-E.mp4\n",
      "18.0\n",
      "O<D< O-D-.mp4\n",
      "21.0\n",
      "D< D-.mp4\n",
      "24.0\n",
      "D< D-.mp4\n",
      "27.0\n",
      "D< D-.mp4\n",
      "30.0\n",
      "D< D-.mp4\n",
      "33.0\n",
      "D<N D-N.mp4\n",
      "36.0\n",
      "consolidating morpheme\n",
      "Moviepy - Building video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-16.mp4.\n",
      "MoviePy - Writing audio in 2-hands-16TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-16.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-16.mp4\n",
      "embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-16.mp4\n",
      "D<O< D-O-.mp4\n",
      "3\n",
      "O<D O-D.mp4\n",
      "6.0\n",
      "O< O-.mp4\n",
      "9.0\n",
      "O< O-.mp4\n",
      "12.0\n",
      "O< O-.mp4\n",
      "15.0\n",
      "O<N O-N.mp4\n",
      "18.0\n",
      "O< O-.mp4\n",
      "21.0\n",
      "O< O-.mp4\n",
      "24.0\n",
      "O< O-.mp4\n",
      "27.0\n",
      "O<N O-N.mp4\n",
      "30.0\n",
      "O<U< O-U-.mp4\n",
      "33.0\n",
      "U<N U-N.mp4\n",
      "36.0\n",
      "consolidating morpheme\n",
      "Moviepy - Building video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-17.mp4.\n",
      "MoviePy - Writing audio in 2-hands-17TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-17.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-17.mp4\n",
      "embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-17.mp4\n",
      "U< U-.mp4\n",
      "3.0\n",
      "U<N U-N.mp4\n",
      "6.0\n",
      "U<O< U-O-.mp4\n",
      "9.0\n",
      "O< O-.mp4\n",
      "12.0\n",
      "O< O-.mp4\n",
      "15.0\n",
      "O<N O-N.mp4\n",
      "18.0\n",
      "O<I< O-I-.mp4\n",
      "21.0\n",
      "I< I-.mp4\n",
      "24.0\n",
      "I< I-.mp4\n",
      "27.0\n",
      "I< I-.mp4\n",
      "30.0\n",
      "I< I-.mp4\n",
      "33.0\n",
      "I<N I-N.mp4\n",
      "36.0\n",
      "consolidating morpheme\n",
      "Moviepy - Building video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-18.mp4.\n",
      "MoviePy - Writing audio in 2-hands-18TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-18.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-18.mp4\n",
      "embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-18.mp4\n",
      "I<D< I-D-.mp4\n",
      "3\n",
      "D<D D-D.mp4\n",
      "6.0\n",
      "D< D-.mp4\n",
      "9.0\n",
      "D<E D-E.mp4\n",
      "12.0\n",
      "D<I< D-I-.mp4\n",
      "15.0\n",
      "I< I-.mp4\n",
      "18.0\n",
      "I< I-.mp4\n",
      "21.0\n",
      "I< I-.mp4\n",
      "24.0\n",
      "I< I-.mp4\n",
      "27.0\n",
      "I<E I-E.mp4\n",
      "30.0\n",
      "I< I-.mp4\n",
      "33.0\n",
      "I< I-.mp4\n",
      "36.0\n",
      "consolidating morpheme\n",
      "Moviepy - Building video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-19.mp4.\n",
      "MoviePy - Writing audio in 2-hands-19TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-19.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-19.mp4\n",
      "embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-19.mp4\n",
      "I<D< I-D-.mp4\n",
      "3\n",
      "D<N D-N.mp4\n",
      "6.0\n",
      "D< D-.mp4\n",
      "9.0\n",
      "D<N D-N.mp4\n",
      "12.0\n",
      "D<U< D-U-.mp4\n",
      "15.0\n",
      "U<E U-E.mp4\n",
      "18.0\n",
      "U< U-.mp4\n",
      "21.0\n",
      "U<E U-E.mp4\n",
      "24.0\n",
      "U< U-.mp4\n",
      "27.0\n",
      "U< U-.mp4\n",
      "30.0\n",
      "U< U-.mp4\n",
      "33.0\n",
      "U< U-.mp4\n",
      "36.0\n",
      "consolidating morpheme\n",
      "Moviepy - Building video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-20.mp4.\n",
      "MoviePy - Writing audio in 2-hands-20TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-20.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-20.mp4\n",
      "embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands-20.mp4\n",
      "U< U-.mp4\n",
      "3.0\n",
      "1\n",
      "21\n",
      "Moviepy - Building video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands.mp4.\n",
      "MoviePy - Writing audio in 2-handsTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready embodied performance/RANDOM-SPEECH/SENTENCE/2/2-hands.mp4\n"
     ]
    }
   ],
   "source": [
    "make_video_clips(sentence_encoding, \"SENTENCE/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0724f494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate randomized word-sentences from existing words \n",
    "sentence_folder = \"embodied performance/RANDOM-SPEECH/SENTENCE/\"\n",
    "\n",
    "def randomize_sentence(sentence_affix):\n",
    "    \n",
    "    #output concat files will be \"2-eyes-sentenceaffix.mp4\" etc\n",
    "    \n",
    "    #first, grab all filenames \n",
    "    all_node_files = {\n",
    "    }\n",
    "    \n",
    "    for i in range(2, 8):\n",
    "        \n",
    "        node_hands = [sentence_folder + str(i) + \"/\" + str(i) + \"-hands-\" + str(j) + \".mp4\" for j in range(21)]\n",
    "        node_eyes = [sentence_folder + str(i) + \"/\" + str(i) + \"-eyes-\" + str(j) + \".mp4\" for j in range(21)]\n",
    "        node_voice = [sentence_folder + str(i) + \"/\" + str(i) + \"-voice-\" + str(j) + \".wav\" for j in range(21)]\n",
    "        node_slap = [sentence_folder + str(i) + \"/\" + str(i) + \"-slap-\" + str(j) + \".mp4\" for j in range(21)]\n",
    "        node_slap_audio = [sentence_folder + str(i) + \"/\" + str(i) + \"-slap-audio-\" + str(j) + \".wav\" \n",
    "                           for j in range(21)]\n",
    "    \n",
    "        node_files = {\n",
    "            \"hands\": node_hands,\n",
    "            \"eyes\": node_eyes,\n",
    "            \"voice\": node_voice,\n",
    "            \"slap\": node_slap,\n",
    "            \"slap-audio\": node_slap_audio\n",
    "        }\n",
    "    \n",
    "        all_node_files[i] = node_files\n",
    "    \n",
    "    #then, get a random word order\n",
    "    order = [i for i in range(21)]\n",
    "    np.random.shuffle(order)\n",
    "    \n",
    "    print(order)\n",
    "    \n",
    "    #for each node:\n",
    "    for node in all_node_files:\n",
    "        node_info = all_node_files[node]\n",
    "        #for each type of action\n",
    "        for action in node_info:\n",
    "            info = node_info[action]\n",
    "            #concatenate using order & export video / audio \n",
    "            if action == \"hands\" or action == \"eyes\" or action == \"slap\":\n",
    "                #order video clips \n",
    "                clips_ordered = [VideoFileClip(info[i]).subclip(0, 27) for i in order]\n",
    "                \n",
    "                #get concat name\n",
    "                concat_clip_name = sentence_folder + str(node) + \"/\" + sentence_affix + \"/\" + sentence_affix \n",
    "                concat_clip_name += \"-\" + str(node) + \"-\" + action + \".mp4\"\n",
    "                \n",
    "                #concatenate & export \n",
    "                concat_clip = concatenate_videofiles(clips_ordered)\n",
    "                concat_clip.write_videofile(concat_clip_name)\n",
    "                \n",
    "            else:\n",
    "                #order audio clips \n",
    "                clips_ordered = [AudioFileClip(info[i]).subclip(0, 27) for i in order]\n",
    "                \n",
    "                #get concat name \n",
    "                concat_clip_name = sentence_folder + str(node) + \"/\" + sentence_affix + \"/\" + sentence_affix \n",
    "                concat_clip_name += \"-\" + str(node) + \"-\" + action + \".wav\"\n",
    "                \n",
    "                #concatenate & export \n",
    "                concat_clip = concatenate_audiofiles(clips_ordered)\n",
    "                concat_clip.write_audiofile(concat_clip_name)\n",
    "\n",
    "                \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9f9dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomize_sentence(\"speaker2\")\n",
    "randomize_sentence(\"speaker3\")\n",
    "randomize_sentence(\"speaker4\")\n",
    "randomize_sentence(\"speaker5\")\n",
    "randomize_sentence(\"speaker6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d9900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_encoding[\"3\"]['hand'][100:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51424678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in embodied performance/RANDOM-SPEECH/SENTENCE/6/6-voice.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "path = \"embodied performance/RANDOM-SPEECH/SENTENCE/6/6-voice\"\n",
    "\n",
    "clips = []\n",
    "for i in range(21):\n",
    "    clip_path = path + \"-\" + str(i) + \".wav\"\n",
    "    if i != 7:\n",
    "        clips.append(AudioFileClip(clip_path).subclip(0, 27))\n",
    "    else:\n",
    "        clips.append(AudioFileClip(clip_path))\n",
    "        \n",
    "\n",
    "full_clip = concatenate_audioclips(clips)\n",
    "full_clip.write_audiofile(path + \".wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f5c26b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
